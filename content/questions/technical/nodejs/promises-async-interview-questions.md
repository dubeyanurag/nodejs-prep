---
title: "Promises and Async/Await Interview Questions"
category: "nodejs-core"
subcategory: "promises-async"
difficulty: "advanced"
estimatedReadTime: 45
questionCount: 38
lastUpdated: "2025-01-08"
tags: ["promises", "async-await", "error-handling", "concurrency", "interview"]
companies: ["Google", "Amazon", "Microsoft", "Meta", "Netflix", "Stripe", "Uber"]
frequency: "very-common"
---

# Promises and Async/Await Interview Questions

## TL;DR - Quick Review (5 minutes)

### Key Concepts
- **Promises**: Objects representing eventual completion/failure of async operations
- **States**: Pending â†’ Fulfilled/Rejected (immutable once settled)
- **Async/Await**: Syntactic sugar over Promises for cleaner async code
- **Error Handling**: try/catch with async/await, .catch() with Promises
- **Concurrency**: Promise.all(), Promise.allSettled(), Promise.race()

### Critical Points for Interviews
- Promise constructor executes synchronously, handlers are async
- Unhandled Promise rejections can crash Node.js applications
- async functions always return Promises
- await only works inside async functions (or top-level in modules)
- Error propagation differs between Promise chains and async/await

### Common Pitfalls
- Forgetting to handle Promise rejections
- Mixing Promise chains with async/await
- Not understanding microtask queue priority
- Creating unnecessary Promise wrappers

---

## Comprehensive Interview Questions

### Frequently Asked Questions (Top 15)

### Q1: Explain how Promises work internally and their three states
**Difficulty:** Mid-Senior | **Companies:** Google, Amazon, Meta | **Frequency:** Very Common

#### Quick Answer (30 seconds)
Promises are objects representing the eventual completion or failure of an asynchronous operation. They have three states: pending (initial), fulfilled (success), or rejected (failure). Once settled (fulfilled/rejected), they're immutable.

#### Detailed Answer (3-5 minutes)
Promises are built on the concept of eventual values. When created, a Promise starts in the "pending" state. The Promise constructor takes an executor function with resolve and reject parameters:

```javascript
const promise = new Promise((resolve, reject) => {
  // Async operation
  if (success) {
    resolve(value); // Transitions to fulfilled
  } else {
    reject(error); // Transitions to rejected
  }
});
```

Key characteristics:
- **Immutability**: Once settled, state cannot change
- **Thenable**: Can be chained with .then(), .catch(), .finally()
- **Microtask scheduling**: Handlers execute in microtask queue
- **Error propagation**: Rejections bubble up the chain until caught

#### Real-World Context
In production systems, Promises handle database queries, API calls, file operations. Understanding state transitions is crucial for debugging async flows and preventing memory leaks.

#### Common Mistakes
- Assuming Promise constructor is async (it's synchronous)
- Not handling rejections (causes unhandled rejection warnings)
- Creating unnecessary Promise wrappers around already-async functions

#### Follow-up Questions
1. What happens if you throw an error in a Promise executor?
2. How do Promise microtasks relate to the event loop?
3. What's the difference between returning a value vs returning a Promise in .then()?

---

### Q2: Compare async/await vs Promise chains - when to use each?
**Difficulty:** Senior | **Companies:** Microsoft, Netflix, Stripe | **Frequency:** Very Common

#### Quick Answer (30 seconds)
Async/await provides cleaner, more readable code that looks synchronous but is asynchronous. Use it for sequential operations and complex error handling. Promise chains are better for functional composition and parallel operations.

#### Detailed Answer (3-5 minutes)
**Async/Await Advantages:**
```javascript
// Cleaner error handling
async function fetchUserData(userId) {
  try {
    const user = await getUserById(userId);
    const profile = await getProfileById(user.profileId);
    const preferences = await getPreferences(user.id);
    return { user, profile, preferences };
  } catch (error) {
    logger.error('Failed to fetch user data:', error);
    throw new UserDataError(error.message);
  }
}
```

**Promise Chain Advantages:**
```javascript
// Better for functional composition
function processPayment(paymentData) {
  return validatePayment(paymentData)
    .then(validated => chargeCard(validated))
    .then(charge => updateDatabase(charge))
    .then(result => sendConfirmation(result))
    .catch(error => handlePaymentError(error));
}
```

**When to use each:**
- **Async/await**: Sequential operations, complex error handling, debugging
- **Promise chains**: Functional programming, transformations, parallel operations

#### Real-World Context
In fintech applications, payment processing often uses Promise chains for transformation pipelines, while user authentication flows use async/await for clearer error handling and debugging.

#### Common Mistakes
- Mixing async/await with .then() in the same function
- Using async/await for parallel operations (should use Promise.all)
- Forgetting that async functions always return Promises

#### Follow-up Questions
1. How would you convert this Promise chain to async/await?
2. What are the performance implications of each approach?
3. How does error handling differ between the two patterns?

---

### Q3: Explain Promise.all(), Promise.allSettled(), and Promise.race()
**Difficulty:** Senior | **Companies:** Amazon, Google, Uber | **Frequency:** Very Common

#### Quick Answer (30 seconds)
Promise.all() waits for all Promises to resolve or any to reject. Promise.allSettled() waits for all to settle regardless of outcome. Promise.race() resolves/rejects with the first settled Promise.

#### Detailed Answer (3-5 minutes)
**Promise.all() - Fail Fast:**
```javascript
async function fetchDashboardData() {
  try {
    const [users, orders, analytics] = await Promise.all([
      fetchUsers(),
      fetchOrders(),
      fetchAnalytics()
    ]);
    return { users, orders, analytics };
  } catch (error) {
    // If ANY request fails, entire operation fails
    throw new DashboardError('Failed to load dashboard data');
  }
}
```

**Promise.allSettled() - Always Complete:**
```javascript
async function fetchOptionalData() {
  const results = await Promise.allSettled([
    fetchCriticalData(),
    fetchOptionalFeature1(),
    fetchOptionalFeature2()
  ]);
  
  const critical = results[0].status === 'fulfilled' 
    ? results[0].value 
    : null;
  
  const optional = results.slice(1)
    .filter(r => r.status === 'fulfilled')
    .map(r => r.value);
    
  return { critical, optional };
}
```

**Promise.race() - First Wins:**
```javascript
async function fetchWithTimeout(url, timeoutMs = 5000) {
  const timeoutPromise = new Promise((_, reject) => 
    setTimeout(() => reject(new Error('Request timeout')), timeoutMs)
  );
  
  return Promise.race([
    fetch(url),
    timeoutPromise
  ]);
}
```

#### Real-World Context
Healthcare systems use Promise.allSettled() to fetch patient data from multiple sources, ensuring partial data is available even if some services fail. Fintech uses Promise.race() for timeout handling in payment processing.

#### Common Mistakes
- Using Promise.all() when you need partial results
- Not handling individual errors in Promise.allSettled()
- Memory leaks with Promise.race() (losing Promises continue running)

#### Follow-up Questions
1. How would you implement a custom Promise.all()?
2. What happens to the "losing" Promises in Promise.race()?
3. When would you use Promise.any() vs Promise.race()?

---

### Q4: How do you handle errors in async/await vs Promise chains?
**Difficulty:** Senior | **Companies:** Meta, Netflix, Stripe | **Frequency:** Very Common

#### Quick Answer (30 seconds)
Async/await uses try/catch blocks for error handling, while Promise chains use .catch(). Async/await provides better stack traces and more intuitive error handling, but Promise chains offer more granular error control.

#### Detailed Answer (3-5 minutes)
**Async/Await Error Handling:**
```javascript
async function processUserRegistration(userData) {
  try {
    // Validation errors
    const validatedData = await validateUserData(userData);
    
    // Database errors
    const user = await createUser(validatedData);
    
    // Email service errors
    await sendWelcomeEmail(user.email);
    
    return { success: true, userId: user.id };
  } catch (error) {
    // Single catch block handles all errors
    if (error instanceof ValidationError) {
      return { success: false, error: 'Invalid user data' };
    }
    if (error instanceof DatabaseError) {
      return { success: false, error: 'Registration failed' };
    }
    // Unexpected errors
    logger.error('Unexpected registration error:', error);
    throw error;
  }
}
```

**Promise Chain Error Handling:**
```javascript
function processPayment(paymentData) {
  return validatePayment(paymentData)
    .catch(error => {
      // Handle validation errors specifically
      throw new PaymentValidationError(error.message);
    })
    .then(validated => chargeCard(validated))
    .catch(error => {
      // Handle payment processing errors
      if (error instanceof PaymentValidationError) {
        throw error; // Re-throw validation errors
      }
      throw new PaymentProcessingError(error.message);
    })
    .then(charge => updateDatabase(charge))
    .catch(error => {
      // Final error handling
      logger.error('Payment processing failed:', error);
      return { success: false, error: error.message };
    });
}
```

#### Real-World Context
In production systems, proper error handling prevents cascading failures. Healthcare applications require detailed error logging for compliance, while fintech needs specific error types for different failure scenarios.

#### Common Mistakes
- Not catching errors in async functions (causes unhandled rejections)
- Catching and re-throwing without adding context
- Using both try/catch and .catch() in the same function

#### Follow-up Questions
1. How do you handle partial failures in a series of async operations?
2. What's the difference between throwing an error and returning a rejected Promise?
3. How do you implement retry logic with exponential backoff?

---

### Q5: Explain the microtask queue and how Promises interact with the event loop
**Difficulty:** Senior | **Companies:** Google, Amazon, Microsoft | **Frequency:** Common

#### Quick Answer (30 seconds)
Promises use the microtask queue, which has higher priority than the macrotask queue. Promise handlers (.then, .catch, .finally) are scheduled as microtasks and execute before the next macrotask (setTimeout, setInterval).

#### Detailed Answer (3-5 minutes)
The event loop processes tasks in this order:
1. **Call Stack** - Synchronous code
2. **Microtask Queue** - Promise handlers, queueMicrotask()
3. **Macrotask Queue** - setTimeout, setInterval, I/O operations

```javascript
console.log('1: Synchronous');

setTimeout(() => console.log('2: Macrotask'), 0);

Promise.resolve().then(() => console.log('3: Microtask'));

queueMicrotask(() => console.log('4: Microtask'));

console.log('5: Synchronous');

// Output: 1, 5, 3, 4, 2
```

**Complex Example:**
```javascript
async function demonstrateEventLoop() {
  console.log('Start');
  
  setTimeout(() => console.log('Timeout 1'), 0);
  
  await Promise.resolve();
  console.log('After await');
  
  setTimeout(() => console.log('Timeout 2'), 0);
  
  return 'Done';
}

demonstrateEventLoop().then(result => console.log(result));
console.log('End');

// Output: Start, End, After await, Done, Timeout 1, Timeout 2
```

#### Real-World Context
Understanding microtask priority is crucial for performance optimization and debugging timing issues in production applications. It affects when database callbacks execute relative to user interface updates.

#### Common Mistakes
- Assuming setTimeout(fn, 0) executes immediately
- Not understanding why Promise handlers execute before timers
- Creating infinite microtask loops that starve the event loop

#### Follow-up Questions
1. What happens if you create an infinite chain of Promise.resolve().then()?
2. How does async/await affect the microtask queue?
3. Why might you use queueMicrotask() instead of Promise.resolve().then()?

---
### Q6: What are the common Promise anti-patterns and how to avoid them?
**Difficulty:** Senior | **Companies:** Netflix, Uber, Stripe | **Frequency:** Common

#### Quick Answer (30 seconds)
Common anti-patterns include the Promise constructor anti-pattern, nested Promise chains (callback hell 2.0), not returning Promises in chains, and creating unnecessary Promise wrappers around already-async functions.

#### Detailed Answer (3-5 minutes)
**1. Promise Constructor Anti-pattern:**
```javascript
// BAD: Wrapping already-async functions
function getUserBad(id) {
  return new Promise((resolve, reject) => {
    database.findUser(id, (err, user) => {
      if (err) reject(err);
      else resolve(user);
    });
  });
}

// GOOD: Use util.promisify or native Promise support
const { promisify } = require('util');
const findUser = promisify(database.findUser);
```

**2. Nested Promise Chains:**
```javascript
// BAD: Callback hell with Promises
function processOrderBad(orderId) {
  return getOrder(orderId)
    .then(order => {
      return getCustomer(order.customerId)
        .then(customer => {
          return processPayment(order.total)
            .then(payment => {
              return updateOrder(orderId, { status: 'paid' });
            });
        });
    });
}

// GOOD: Flat Promise chain or async/await
async function processOrderGood(orderId) {
  const order = await getOrder(orderId);
  const customer = await getCustomer(order.customerId);
  const payment = await processPayment(order.total);
  return updateOrder(orderId, { status: 'paid' });
}
```

**3. Not Returning Promises:**
```javascript
// BAD: Breaking the chain
function updateUserProfile(userId, data) {
  return getUser(userId)
    .then(user => {
      updateDatabase(user.id, data); // Missing return!
      // Chain breaks here
    });
}

// GOOD: Return the Promise
function updateUserProfile(userId, data) {
  return getUser(userId)
    .then(user => updateDatabase(user.id, data));
}
```

#### Real-World Context
These anti-patterns are common in legacy codebases being migrated from callbacks to Promises. They can cause subtle bugs, memory leaks, and make code harder to test and maintain.

#### Common Mistakes
- Wrapping Promise-returning functions in new Promise()
- Not understanding that .then() must return a value or Promise
- Mixing callback patterns with Promise patterns

#### Follow-up Questions
1. How would you refactor a deeply nested callback structure to Promises?
2. What tools can help identify Promise anti-patterns in code reviews?
3. How do you handle mixed callback/Promise APIs in the same codebase?

---

### Q7: How do you implement Promise cancellation and timeout handling?
**Difficulty:** Senior | **Companies:** Google, Amazon, Meta | **Frequency:** Common

#### Quick Answer (30 seconds)
JavaScript Promises aren't natively cancellable, but you can implement cancellation using AbortController, timeout wrappers, or cancellation tokens. Common patterns include Promise.race() with timeout Promises and cleanup functions.

#### Detailed Answer (3-5 minutes)
**1. Timeout Implementation:**
```javascript
function withTimeout(promise, timeoutMs, errorMessage = 'Operation timed out') {
  const timeoutPromise = new Promise((_, reject) => {
    const timeoutId = setTimeout(() => {
      reject(new Error(errorMessage));
    }, timeoutMs);
    
    // Cleanup timeout if main promise resolves first
    promise.finally(() => clearTimeout(timeoutId));
  });
  
  return Promise.race([promise, timeoutPromise]);
}

// Usage
async function fetchUserWithTimeout(userId) {
  try {
    return await withTimeout(
      fetchUser(userId), 
      5000, 
      'User fetch timed out'
    );
  } catch (error) {
    if (error.message.includes('timed out')) {
      // Handle timeout specifically
      return null;
    }
    throw error;
  }
}
```

**2. AbortController Pattern:**
```javascript
async function fetchWithCancellation(url, signal) {
  try {
    const response = await fetch(url, { signal });
    return await response.json();
  } catch (error) {
    if (error.name === 'AbortError') {
      console.log('Request was cancelled');
      return null;
    }
    throw error;
  }
}

// Usage
const controller = new AbortController();
const promise = fetchWithCancellation('/api/data', controller.signal);

// Cancel after 3 seconds
setTimeout(() => controller.abort(), 3000);
```

**3. Cancellation Token Pattern:**
```javascript
class CancellationToken {
  constructor() {
    this.cancelled = false;
    this.reason = null;
  }
  
  cancel(reason = 'Operation cancelled') {
    this.cancelled = true;
    this.reason = reason;
  }
  
  throwIfCancelled() {
    if (this.cancelled) {
      throw new Error(this.reason);
    }
  }
}

async function longRunningOperation(token) {
  for (let i = 0; i < 1000; i++) {
    token.throwIfCancelled();
    
    await processItem(i);
    
    // Check cancellation periodically
    if (i % 100 === 0) {
      token.throwIfCancelled();
    }
  }
}
```

#### Real-World Context
In production systems, timeout handling prevents resource leaks and improves user experience. Healthcare applications need cancellation for long-running data processing, while fintech uses timeouts for payment processing to prevent hanging transactions.

#### Common Mistakes
- Not cleaning up resources when operations are cancelled
- Implementing cancellation that doesn't actually stop the underlying operation
- Not handling AbortError properly in fetch requests

#### Follow-up Questions
1. How would you implement a retry mechanism with exponential backoff?
2. What's the difference between cancellation and timeout?
3. How do you handle cleanup when a Promise is cancelled?

---

### Company-Specific Questions (10 questions)

### Q8: [Google] How would you implement a Promise-based rate limiter?
**Difficulty:** Senior | **Companies:** Google, Stripe | **Frequency:** Common

#### Quick Answer (30 seconds)
Implement a rate limiter using a queue of pending Promises, tracking request timestamps, and resolving Promises when rate limits allow. Use sliding window or token bucket algorithms.

#### Detailed Answer (3-5 minutes)
```javascript
class PromiseRateLimiter {
  constructor(maxRequests, windowMs) {
    this.maxRequests = maxRequests;
    this.windowMs = windowMs;
    this.requests = [];
    this.queue = [];
  }
  
  async execute(fn) {
    return new Promise((resolve, reject) => {
      this.queue.push({ fn, resolve, reject });
      this.processQueue();
    });
  }
  
  processQueue() {
    if (this.queue.length === 0) return;
    
    const now = Date.now();
    
    // Remove old requests outside the window
    this.requests = this.requests.filter(
      timestamp => now - timestamp < this.windowMs
    );
    
    // If we can make more requests
    if (this.requests.length < this.maxRequests) {
      const { fn, resolve, reject } = this.queue.shift();
      this.requests.push(now);
      
      // Execute the function
      Promise.resolve(fn())
        .then(resolve)
        .catch(reject)
        .finally(() => {
          // Process next item in queue
          setTimeout(() => this.processQueue(), 0);
        });
    } else {
      // Wait until we can make the next request
      const oldestRequest = Math.min(...this.requests);
      const waitTime = this.windowMs - (now - oldestRequest);
      setTimeout(() => this.processQueue(), waitTime);
    }
  }
}

// Usage
const limiter = new PromiseRateLimiter(5, 1000); // 5 requests per second

async function makeApiCall(data) {
  return limiter.execute(() => fetch('/api/endpoint', {
    method: 'POST',
    body: JSON.stringify(data)
  }));
}
```

#### Real-World Context
Rate limiting is crucial for API integrations, preventing service overload, and complying with third-party API limits. Google's services often require sophisticated rate limiting for optimal performance.

#### Follow-up Questions
1. How would you implement distributed rate limiting across multiple servers?
2. What's the difference between token bucket and sliding window algorithms?
3. How do you handle burst traffic while maintaining rate limits?

---

### Q9: [Amazon] Implement a Promise-based circuit breaker pattern
**Difficulty:** Senior | **Companies:** Amazon, Netflix, Uber | **Frequency:** Common

#### Quick Answer (30 seconds)
A circuit breaker prevents cascading failures by monitoring failure rates and temporarily blocking requests when a service is unhealthy. It has three states: Closed (normal), Open (blocking), and Half-Open (testing recovery).

#### Detailed Answer (3-5 minutes)
```javascript
class CircuitBreaker {
  constructor(options = {}) {
    this.failureThreshold = options.failureThreshold || 5;
    this.recoveryTimeout = options.recoveryTimeout || 60000;
    this.monitoringPeriod = options.monitoringPeriod || 10000;
    
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.failures = 0;
    this.lastFailureTime = null;
    this.successCount = 0;
  }
  
  async execute(fn) {
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime >= this.recoveryTimeout) {
        this.state = 'HALF_OPEN';
        this.successCount = 0;
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }
    
    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  onSuccess() {
    this.failures = 0;
    
    if (this.state === 'HALF_OPEN') {
      this.successCount++;
      if (this.successCount >= 3) { // Require 3 successes to close
        this.state = 'CLOSED';
      }
    }
  }
  
  onFailure() {
    this.failures++;
    this.lastFailureTime = Date.now();
    
    if (this.failures >= this.failureThreshold) {
      this.state = 'OPEN';
    }
  }
  
  getState() {
    return {
      state: this.state,
      failures: this.failures,
      lastFailureTime: this.lastFailureTime
    };
  }
}

// Usage with database operations
const dbCircuitBreaker = new CircuitBreaker({
  failureThreshold: 3,
  recoveryTimeout: 30000
});

async function getUserFromDatabase(userId) {
  return dbCircuitBreaker.execute(async () => {
    const user = await database.findById(userId);
    if (!user) {
      throw new Error('User not found');
    }
    return user;
  });
}
```

#### Real-World Context
Amazon's microservices architecture relies heavily on circuit breakers to prevent cascading failures. When one service becomes unhealthy, circuit breakers prevent it from taking down dependent services.

#### Follow-up Questions
1. How would you implement circuit breaker metrics and monitoring?
2. What's the difference between fail-fast and fail-safe strategies?
3. How do you handle partial failures in a distributed system?

---

### Advanced/Expert Level Questions (8 questions)

### Q10: Explain Promise memory leaks and how to prevent them
**Difficulty:** Staff | **Companies:** Meta, Google, Netflix | **Frequency:** Occasional

#### Quick Answer (30 seconds)
Promise memory leaks occur when Promises hold references to large objects, create infinite chains, or aren't properly cleaned up in long-running applications. Prevention involves proper cleanup, avoiding circular references, and using weak references where appropriate.

#### Detailed Answer (3-5 minutes)
**Common Memory Leak Scenarios:**

**1. Uncleaned Event Listeners:**
```javascript
// BAD: Memory leak
function createPromiseWithLeak() {
  return new Promise((resolve) => {
    const largeData = new Array(1000000).fill('data');
    
    // Event listener holds reference to largeData
    process.on('SIGINT', () => {
      console.log('Cleanup', largeData.length);
      resolve();
    });
  });
}

// GOOD: Proper cleanup
function createPromiseWithCleanup() {
  return new Promise((resolve) => {
    const largeData = new Array(1000000).fill('data');
    
    const cleanup = () => {
      console.log('Cleanup', largeData.length);
      process.removeListener('SIGINT', cleanup);
      resolve();
    };
    
    process.on('SIGINT', cleanup);
  });
}
```

**2. Infinite Promise Chains:**
```javascript
// BAD: Creates infinite chain
function infiniteChain() {
  return Promise.resolve()
    .then(() => infiniteChain()); // Stack overflow + memory leak
}

// GOOD: Controlled recursion
function controlledChain(count = 0, maxCount = 1000) {
  if (count >= maxCount) return Promise.resolve();
  
  return Promise.resolve()
    .then(() => controlledChain(count + 1, maxCount));
}
```

**3. Closure Memory Leaks:**
```javascript
// BAD: Closure holds large objects
function processLargeDataset(dataset) {
  const largeProcessedData = dataset.map(item => ({
    ...item,
    processed: true,
    metadata: new Array(1000).fill('meta')
  }));
  
  // This Promise closure holds reference to largeProcessedData
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve(largeProcessedData.length); // Only need the length
    }, 1000);
  });
}

// GOOD: Extract only needed data
function processLargeDatasetFixed(dataset) {
  const largeProcessedData = dataset.map(item => ({
    ...item,
    processed: true,
    metadata: new Array(1000).fill('meta')
  }));
  
  const resultLength = largeProcessedData.length;
  
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve(resultLength);
    }, 1000);
  });
}
```

#### Real-World Context
In production applications, especially long-running Node.js servers, Promise memory leaks can cause gradual memory growth leading to out-of-memory crashes. This is particularly problematic in healthcare systems processing large datasets or fintech applications handling high-frequency transactions.

#### Common Mistakes
- Not removing event listeners in Promise executors
- Creating circular references between Promises and objects
- Holding references to large objects in Promise closures

#### Follow-up Questions
1. How would you debug Promise memory leaks in production?
2. What tools can help identify Promise-related memory issues?
3. How do WeakMap and WeakSet help prevent memory leaks?

---

### Q11: Implement a custom Promise.all() with concurrency limiting
**Difficulty:** Staff | **Companies:** Google, Amazon, Stripe | **Frequency:** Occasional

#### Quick Answer (30 seconds)
A concurrency-limited Promise.all() processes Promises in batches to prevent overwhelming system resources. It maintains a pool of active Promises and queues remaining ones until slots become available.

#### Detailed Answer (3-5 minutes)
```javascript
async function promiseAllWithConcurrency(promises, concurrency = 3) {
  if (concurrency <= 0) {
    throw new Error('Concurrency must be greater than 0');
  }
  
  const results = new Array(promises.length);
  const executing = [];
  
  for (let i = 0; i < promises.length; i++) {
    const promise = Promise.resolve(promises[i]).then(
      value => {
        results[i] = { status: 'fulfilled', value };
      },
      reason => {
        results[i] = { status: 'rejected', reason };
      }
    );
    
    executing.push(promise);
    
    if (executing.length >= concurrency) {
      await Promise.race(executing);
      // Remove completed promises
      for (let j = executing.length - 1; j >= 0; j--) {
        if (results[j] !== undefined) {
          executing.splice(j, 1);
        }
      }
    }
  }
  
  // Wait for remaining promises
  await Promise.all(executing);
  
  // Check for rejections and throw if any (like Promise.all behavior)
  const rejections = results.filter(r => r.status === 'rejected');
  if (rejections.length > 0) {
    throw rejections[0].reason;
  }
  
  return results.map(r => r.value);
}

// Alternative implementation with better performance
class ConcurrencyLimiter {
  constructor(concurrency = 3) {
    this.concurrency = concurrency;
    this.running = 0;
    this.queue = [];
  }
  
  async add(promiseFactory) {
    return new Promise((resolve, reject) => {
      this.queue.push({
        promiseFactory,
        resolve,
        reject
      });
      this.process();
    });
  }
  
  async process() {
    if (this.running >= this.concurrency || this.queue.length === 0) {
      return;
    }
    
    this.running++;
    const { promiseFactory, resolve, reject } = this.queue.shift();
    
    try {
      const result = await promiseFactory();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.running--;
      this.process();
    }
  }
}

// Usage
async function fetchUsersWithLimit(userIds) {
  const limiter = new ConcurrencyLimiter(5);
  
  const promises = userIds.map(id => 
    limiter.add(() => fetchUser(id))
  );
  
  return Promise.all(promises);
}
```

#### Real-World Context
Concurrency limiting is essential when making many API calls, database queries, or file operations. Without limits, applications can overwhelm external services or exhaust system resources, leading to timeouts and failures.

#### Follow-up Questions
1. How would you implement priority queuing in the concurrency limiter?
2. What's the difference between concurrency and parallelism in this context?
3. How do you handle backpressure when the queue grows too large?

---

### Behavioral Questions About Debugging Async Code (5 questions)

### Q12: Describe a time when you had to debug a complex async issue in production
**Difficulty:** Senior | **Companies:** All | **Frequency:** Very Common

#### Quick Answer (30 seconds)
Focus on a specific incident involving race conditions, deadlocks, or memory leaks in async code. Describe your systematic debugging approach, tools used, and how you prevented similar issues.

#### Detailed Answer (3-5 minutes)
**Situation:** At a fintech company, we had intermittent payment processing failures where transactions would hang indefinitely, causing customer complaints and revenue loss.

**Task:** Debug and fix the async payment processing pipeline that was failing randomly in production.

**Action:**
1. **Initial Investigation:** Added comprehensive logging to track Promise states and timing
2. **Reproduction:** Created load testing scenarios to reproduce the issue locally
3. **Root Cause Analysis:** Discovered a race condition in our Promise.all() implementation:

```javascript
// Problematic code
async function processPayment(paymentData) {
  const [validation, riskCheck, cardAuth] = await Promise.all([
    validatePayment(paymentData),
    performRiskCheck(paymentData),
    authorizeCard(paymentData)
  ]);
  
  // Race condition: sometimes riskCheck would modify paymentData
  // while cardAuth was still using the original data
  return finalizePayment(validation, riskCheck, cardAuth);
}
```

4. **Solution Implementation:**
```javascript
// Fixed version with proper data isolation
async function processPayment(paymentData) {
  const immutableData = Object.freeze({ ...paymentData });
  
  const [validation, riskCheck, cardAuth] = await Promise.all([
    validatePayment(immutableData),
    performRiskCheck({ ...immutableData }), // Separate copy for risk check
    authorizeCard(immutableData)
  ]);
  
  return finalizePayment(validation, riskCheck, cardAuth);
}
```

5. **Prevention Measures:**
   - Implemented immutable data patterns
   - Added unit tests for concurrent scenarios
   - Created monitoring alerts for hanging transactions

**Result:** Reduced payment failures by 95% and implemented systematic async debugging practices across the team.

#### Follow-up Questions
1. What tools do you use for debugging async issues?
2. How do you prevent race conditions in async code?
3. Describe your approach to testing async code thoroughly.

---

### Q13: How do you handle async error propagation in a microservices architecture?
**Difficulty:** Senior | **Companies:** Amazon, Netflix, Uber | **Frequency:** Common

#### Quick Answer (30 seconds)
Implement structured error handling with proper error types, correlation IDs for tracing, circuit breakers for resilience, and centralized logging. Use async/await with try/catch blocks and ensure errors are properly categorized and handled at service boundaries.

#### Detailed Answer (3-5 minutes)
**Healthcare System Example:**

```javascript
// Error types for different failure scenarios
class ServiceError extends Error {
  constructor(message, code, service, correlationId) {
    super(message);
    this.code = code;
    this.service = service;
    this.correlationId = correlationId;
    this.timestamp = new Date().toISOString();
  }
}

class PatientDataService {
  async getPatientRecord(patientId, correlationId) {
    try {
      const [demographics, medical, insurance] = await Promise.allSettled([
        this.getDemographics(patientId, correlationId),
        this.getMedicalHistory(patientId, correlationId),
        this.getInsuranceInfo(patientId, correlationId)
      ]);
      
      // Handle partial failures gracefully
      const result = {
        patientId,
        demographics: demographics.status === 'fulfilled' ? demographics.value : null,
        medical: medical.status === 'fulfilled' ? medical.value : null,
        insurance: insurance.status === 'fulfilled' ? insurance.value : null,
        errors: []
      };
      
      // Log partial failures but don't fail the entire request
      [demographics, medical, insurance].forEach((settled, index) => {
        if (settled.status === 'rejected') {
          const serviceName = ['demographics', 'medical', 'insurance'][index];
          const error = new ServiceError(
            `Failed to fetch ${serviceName}`,
            'PARTIAL_FAILURE',
            serviceName,
            correlationId
          );
          result.errors.push(error);
          this.logger.warn('Partial service failure', error);
        }
      });
      
      return result;
    } catch (error) {
      const serviceError = new ServiceError(
        'Failed to fetch patient record',
        'PATIENT_FETCH_ERROR',
        'patient-service',
        correlationId
      );
      
      this.logger.error('Patient record fetch failed', {
        error: serviceError,
        originalError: error,
        patientId
      });
      
      throw serviceError;
    }
  }
  
  async getDemographics(patientId, correlationId) {
    try {
      return await this.httpClient.get(`/demographics/${patientId}`, {
        headers: { 'X-Correlation-ID': correlationId }
      });
    } catch (error) {
      if (error.response?.status === 404) {
        throw new ServiceError(
          'Patient demographics not found',
          'DEMOGRAPHICS_NOT_FOUND',
          'demographics-service',
          correlationId
        );
      }
      throw new ServiceError(
        'Demographics service unavailable',
        'DEMOGRAPHICS_SERVICE_ERROR',
        'demographics-service',
        correlationId
      );
    }
  }
}
```

**Error Handling Strategy:**
1. **Structured Errors:** Custom error classes with context
2. **Correlation IDs:** Track requests across services
3. **Graceful Degradation:** Handle partial failures
4. **Circuit Breakers:** Prevent cascading failures
5. **Centralized Logging:** Aggregate errors for analysis

#### Real-World Context
In healthcare systems, partial data availability is often acceptable (show what's available), while in fintech, data consistency is critical (fail fast if any component fails).

#### Follow-up Questions
1. How do you implement distributed tracing for async operations?
2. What's your strategy for handling timeout errors across services?
3. How do you test error propagation in microservices?

---

### Real-World Scenarios from Fintech and Healthcare (5 questions)

### Q14: Design an async payment processing system that handles high concurrency
**Difficulty:** Staff | **Companies:** Stripe, Square, PayPal | **Frequency:** Common

#### Quick Answer (30 seconds)
Design a system with async queues, idempotency keys, distributed locks, and proper error handling. Use Promise-based workflows with timeout handling, retry logic, and transaction state management.

#### Detailed Answer (3-5 minutes)
```javascript
class PaymentProcessor {
  constructor(options = {}) {
    this.redis = options.redis;
    this.database = options.database;
    this.paymentGateway = options.paymentGateway;
    this.maxRetries = options.maxRetries || 3;
    this.timeoutMs = options.timeoutMs || 30000;
  }
  
  async processPayment(paymentRequest) {
    const { idempotencyKey, amount, currency, paymentMethod } = paymentRequest;
    const correlationId = generateCorrelationId();
    
    // Check for duplicate requests using idempotency key
    const existingResult = await this.checkIdempotency(idempotencyKey);
    if (existingResult) {
      return existingResult;
    }
    
    // Acquire distributed lock to prevent concurrent processing
    const lockKey = `payment_lock:${idempotencyKey}`;
    const lock = await this.acquireLock(lockKey, 60000); // 60 second lock
    
    try {
      return await this.executePaymentWorkflow({
        idempotencyKey,
        amount,
        currency,
        paymentMethod,
        correlationId
      });
    } finally {
      await this.releaseLock(lock);
    }
  }
  
  async executePaymentWorkflow(paymentData) {
    const { idempotencyKey, correlationId } = paymentData;
    
    try {
      // Step 1: Validate payment data
      await this.validatePayment(paymentData);
      
      // Step 2: Perform fraud/risk checks
      const riskAssessment = await this.performRiskCheck(paymentData);
      if (riskAssessment.blocked) {
        throw new PaymentError('Payment blocked by risk check', 'RISK_BLOCKED');
      }
      
      // Step 3: Reserve funds (pre-authorization)
      const preAuth = await this.preAuthorizePayment(paymentData);
      
      // Step 4: Process the actual payment
      const paymentResult = await this.withTimeout(
        this.chargePayment(preAuth),
        this.timeoutMs
      );
      
      // Step 5: Update database and send notifications
      await Promise.all([
        this.updatePaymentRecord(paymentResult),
        this.sendPaymentNotification(paymentResult),
        this.updateMerchantBalance(paymentResult)
      ]);
      
      // Store result for idempotency
      await this.storeIdempotencyResult(idempotencyKey, paymentResult);
      
      return {
        success: true,
        paymentId: paymentResult.id,
        status: 'completed',
        correlationId
      };
      
    } catch (error) {
      // Comprehensive error handling with retry logic
      if (this.isRetryableError(error) && paymentData.retryCount < this.maxRetries) {
        await this.scheduleRetry(paymentData, error);
        return { success: false, status: 'retrying', correlationId };
      }
      
      // Log error with full context
      this.logger.error('Payment processing failed', {
        error,
        paymentData,
        correlationId
      });
      
      // Store failure for idempotency
      const failureResult = {
        success: false,
        error: error.message,
        errorCode: error.code,
        correlationId
      };
      
      await this.storeIdempotencyResult(idempotencyKey, failureResult);
      return failureResult;
    }
  }
  
  async withTimeout(promise, timeoutMs) {
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Payment timeout')), timeoutMs);
    });
    
    return Promise.race([promise, timeoutPromise]);
  }
  
  async acquireLock(key, ttlMs) {
    const lockValue = generateUniqueId();
    const result = await this.redis.set(key, lockValue, 'PX', ttlMs, 'NX');
    
    if (result === 'OK') {
      return { key, value: lockValue };
    }
    
    throw new Error('Failed to acquire payment lock');
  }
  
  async releaseLock(lock) {
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `;
    
    await this.redis.eval(script, 1, lock.key, lock.value);
  }
  
  isRetryableError(error) {
    const retryableCodes = [
      'NETWORK_ERROR',
      'GATEWAY_TIMEOUT',
      'SERVICE_UNAVAILABLE',
      'RATE_LIMITED'
    ];
    
    return retryableCodes.includes(error.code);
  }
  
  async scheduleRetry(paymentData, error) {
    const retryDelay = Math.pow(2, paymentData.retryCount) * 1000; // Exponential backoff
    
    setTimeout(() => {
      this.processPayment({
        ...paymentData,
        retryCount: (paymentData.retryCount || 0) + 1
      });
    }, retryDelay);
  }
}
```

#### Real-World Context
This design handles the complexity of financial transactions where consistency, idempotency, and error handling are critical. The system must handle network failures, duplicate requests, and partial failures while maintaining data integrity.

#### Follow-up Questions
1. How would you handle partial refunds in this system?
2. What monitoring and alerting would you implement?
3. How do you ensure PCI compliance in the async processing pipeline?

---

### Q15: Implement async patient data aggregation with HIPAA compliance
**Difficulty:** Staff | **Companies:** Epic, Cerner, Teladoc | **Frequency:** Occasional

#### Quick Answer (30 seconds)
Design a system that aggregates patient data from multiple sources while maintaining HIPAA compliance through encryption, audit logging, access controls, and proper error handling that doesn't leak sensitive information.

#### Detailed Answer (3-5 minutes)
```javascript
class HIPAACompliantPatientAggregator {
  constructor(options = {}) {
    this.encryptionService = options.encryptionService;
    this.auditLogger = options.auditLogger;
    this.accessControl = options.accessControl;
    this.dataSources = options.dataSources;
  }
  
  async aggregatePatientData(patientId, requestingUserId, purpose) {
    const auditContext = {
      patientId: this.hashPII(patientId),
      requestingUserId,
      purpose,
      timestamp: new Date().toISOString(),
      correlationId: generateCorrelationId()
    };
    
    try {
      // Step 1: Verify access permissions
      await this.verifyAccess(patientId, requestingUserId, purpose);
      
      // Step 2: Log access attempt
      await this.auditLogger.logAccess({
        ...auditContext,
        action: 'PATIENT_DATA_ACCESS_ATTEMPT'
      });
      
      // Step 3: Fetch data from multiple sources with encryption
      const dataPromises = this.dataSources.map(source => 
        this.fetchEncryptedData(source, patientId, auditContext)
      );
      
      const results = await Promise.allSettled(dataPromises);
      
      // Step 4: Process results and handle partial failures
      const aggregatedData = await this.processDataResults(results, auditContext);
      
      // Step 5: Apply data minimization (only return what's needed)
      const minimizedData = this.applyDataMinimization(aggregatedData, purpose);
      
      // Step 6: Log successful access
      await this.auditLogger.logAccess({
        ...auditContext,
        action: 'PATIENT_DATA_ACCESS_SUCCESS',
        dataTypes: Object.keys(minimizedData)
      });
      
      return {
        success: true,
        data: minimizedData,
        correlationId: auditContext.correlationId
      };
      
    } catch (error) {
      // Log access failure without exposing sensitive data
      await this.auditLogger.logAccess({
        ...auditContext,
        action: 'PATIENT_DATA_ACCESS_FAILURE',
        errorCode: error.code,
        // Never log actual error message (might contain PHI)
        errorType: error.constructor.name
      });
      
      // Return sanitized error
      throw new HIPAAError('Access denied or data unavailable', error.code);
    }
  }
  
  async fetchEncryptedData(source, patientId, auditContext) {
    const startTime = Date.now();
    
    try {
      // Fetch encrypted data
      const encryptedData = await source.getData(patientId);
      
      // Decrypt data
      const decryptedData = await this.encryptionService.decrypt(encryptedData);
      
      // Log data source access
      await this.auditLogger.logDataSourceAccess({
        ...auditContext,
        dataSource: source.name,
        responseTime: Date.now() - startTime,
        status: 'SUCCESS'
      });
      
      return {
        source: source.name,
        data: decryptedData,
        timestamp: new Date().toISOString()
      };
      
    } catch (error) {
      // Log failure without sensitive details
      await this.auditLogger.logDataSourceAccess({
        ...auditContext,
        dataSource: source.name,
        responseTime: Date.now() - startTime,
        status: 'FAILURE',
        errorCode: error.code
      });
      
      throw new DataSourceError(`Failed to fetch from ${source.name}`, error.code);
    }
  }
  
  async processDataResults(results, auditContext) {
    const aggregatedData = {};
    const errors = [];
    
    results.forEach((result, index) => {
      if (result.status === 'fulfilled') {
        const { source, data } = result.value;
        aggregatedData[source] = data;
      } else {
        errors.push({
          source: this.dataSources[index].name,
          error: result.reason.code
        });
      }
    });
    
    // Log partial failures
    if (errors.length > 0) {
      await this.auditLogger.logPartialFailure({
        ...auditContext,
        failedSources: errors.map(e => e.source),
        successfulSources: Object.keys(aggregatedData)
      });
    }
    
    return aggregatedData;
  }
  
  applyDataMinimization(data, purpose) {
    // Only return data fields necessary for the stated purpose
    const purposeFieldMap = {
      'TREATMENT': ['demographics', 'medical_history', 'current_medications'],
      'BILLING': ['demographics', 'insurance', 'billing_history'],
      'RESEARCH': ['anonymized_medical_data'] // No direct identifiers
    };
    
    const allowedFields = purposeFieldMap[purpose] || [];
    const minimizedData = {};
    
    allowedFields.forEach(field => {
      if (data[field]) {
        minimizedData[field] = data[field];
      }
    });
    
    return minimizedData;
  }
  
  async verifyAccess(patientId, userId, purpose) {
    const hasAccess = await this.accessControl.verifyPatientAccess(
      userId, 
      patientId, 
      purpose
    );
    
    if (!hasAccess) {
      throw new AccessDeniedError('Insufficient permissions for patient data');
    }
  }
  
  hashPII(data) {
    // Hash PII for audit logs (one-way hash for privacy)
    return this.encryptionService.hash(data);
  }
}

// Usage
const aggregator = new HIPAACompliantPatientAggregator({
  encryptionService: new EncryptionService(),
  auditLogger: new HIPAAAuditLogger(),
  accessControl: new AccessControlService(),
  dataSources: [
    new EHRDataSource(),
    new LabDataSource(),
    new ImagingDataSource()
  ]
});

async function getPatientSummary(patientId, doctorId) {
  try {
    const result = await aggregator.aggregatePatientData(
      patientId, 
      doctorId, 
      'TREATMENT'
    );
    return result.data;
  } catch (error) {
    // Handle HIPAA-compliant error response
    return { error: 'Unable to retrieve patient data' };
  }
}
```

#### Real-World Context
Healthcare systems must balance data accessibility with privacy protection. This design ensures that async operations maintain audit trails, encrypt data in transit and at rest, and implement proper access controls while handling the complexity of multiple data sources.

#### Follow-up Questions
1. How do you handle data retention policies in async processing?
2. What's your approach to handling consent management in async workflows?
3. How do you implement break-glass access for emergency situations?

---

### Q16: Final Advanced Question - Implement a Promise-based distributed lock system
**Difficulty:** Staff | **Companies:** Google, Amazon, Netflix | **Frequency:** Rare

#### Quick Answer (30 seconds)
Implement distributed locks using Redis with proper timeout handling, lock renewal, and deadlock prevention. Use Promise-based APIs with proper cleanup and error handling to ensure locks are always released.

#### Detailed Answer (3-5 minutes)
```javascript
class DistributedLock {
  constructor(redis, options = {}) {
    this.redis = redis;
    this.defaultTTL = options.defaultTTL || 30000; // 30 seconds
    this.renewalInterval = options.renewalInterval || 10000; // 10 seconds
    this.maxRetries = options.maxRetries || 3;
    this.retryDelay = options.retryDelay || 1000;
  }
  
  async acquire(lockKey, ttl = this.defaultTTL) {
    const lockValue = this.generateLockValue();
    const acquired = await this.tryAcquire(lockKey, lockValue, ttl);
    
    if (!acquired) {
      throw new LockAcquisitionError(`Failed to acquire lock: ${lockKey}`);
    }
    
    return new Lock(this.redis, lockKey, lockValue, ttl, this.renewalInterval);
  }
  
  async acquireWithRetry(lockKey, ttl = this.defaultTTL) {
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      try {
        return await this.acquire(lockKey, ttl);
      } catch (error) {
        if (attempt === this.maxRetries) {
          throw error;
        }
        
        // Exponential backoff with jitter
        const delay = this.retryDelay * Math.pow(2, attempt - 1) + 
                     Math.random() * 1000;
        await this.sleep(delay);
      }
    }
  }
  
  async tryAcquire(lockKey, lockValue, ttl) {
    const script = `
      if redis.call("exists", KEYS[1]) == 0 then
        redis.call("set", KEYS[1], ARGV[1], "PX", ARGV[2])
        return 1
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(script, 1, lockKey, lockValue, ttl);
    return result === 1;
  }
  
  generateLockValue() {
    return `${process.pid}-${Date.now()}-${Math.random()}`;
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

class Lock {
  constructor(redis, key, value, ttl, renewalInterval) {
    this.redis = redis;
    this.key = key;
    this.value = value;
    this.ttl = ttl;
    this.renewalInterval = renewalInterval;
    this.renewalTimer = null;
    this.released = false;
    
    this.startRenewal();
  }
  
  startRenewal() {
    this.renewalTimer = setInterval(async () => {
      if (this.released) {
        clearInterval(this.renewalTimer);
        return;
      }
      
      try {
        await this.renew();
      } catch (error) {
        console.error('Failed to renew lock:', error);
        // Lock might have expired, stop renewal
        clearInterval(this.renewalTimer);
      }
    }, this.renewalInterval);
  }
  
  async renew() {
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        redis.call("pexpire", KEYS[1], ARGV[2])
        return 1
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(script, 1, this.key, this.value, this.ttl);
    return result === 1;
  }
  
  async release() {
    if (this.released) {
      return true;
    }
    
    this.released = true;
    
    if (this.renewalTimer) {
      clearInterval(this.renewalTimer);
    }
    
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(script, 1, this.key, this.value);
    return result === 1;
  }
  
  async extend(additionalTTL) {
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        local current_ttl = redis.call("pttl", KEYS[1])
        if current_ttl > 0 then
          redis.call("pexpire", KEYS[1], current_ttl + ARGV[2])
          return current_ttl + ARGV[2]
        else
          return -1
        end
      else
        return 0
      end
    `;
    
    const result = await this.redis.eval(script, 1, this.key, this.value, additionalTTL);
    return result;
  }
}

// Usage with Promise-based workflow
class CriticalSectionExecutor {
  constructor(distributedLock) {
    this.distributedLock = distributedLock;
  }
  
  async executeWithLock(lockKey, criticalSection, options = {}) {
    const lock = await this.distributedLock.acquireWithRetry(
      lockKey, 
      options.ttl
    );
    
    try {
      // Execute critical section
      const result = await criticalSection();
      return result;
    } finally {
      // Always release the lock
      await lock.release();
    }
  }
  
  async executeWithAutoExtend(lockKey, longRunningTask, options = {}) {
    const lock = await this.distributedLock.acquire(lockKey, options.ttl);
    
    try {
      // For long-running tasks, extend lock as needed
      const taskPromise = longRunningTask();
      
      // Monitor task progress and extend lock if needed
      const extendPromise = this.monitorAndExtend(lock, taskPromise);
      
      const result = await Promise.race([taskPromise, extendPromise]);
      return result;
    } finally {
      await lock.release();
    }
  }
  
  async monitorAndExtend(lock, taskPromise) {
    const checkInterval = 5000; // Check every 5 seconds
    
    while (!taskPromise.isResolved) {
      await new Promise(resolve => setTimeout(resolve, checkInterval));
      
      // Extend lock if task is still running
      if (!taskPromise.isResolved) {
        await lock.extend(30000); // Extend by 30 seconds
      }
    }
  }
}

// Real-world usage example
async function processUniqueUserAction(userId, action) {
  const lockKey = `user_action:${userId}`;
  const executor = new CriticalSectionExecutor(distributedLock);
  
  return executor.executeWithLock(lockKey, async () => {
    // Critical section - ensure only one action per user at a time
    const user = await getUserById(userId);
    const result = await performAction(user, action);
    await updateUserState(userId, result);
    return result;
  }, { ttl: 60000 }); // 60 second lock
}
```

#### Real-World Context
Distributed locks are essential in microservices architectures to prevent race conditions, ensure data consistency, and coordinate access to shared resources. They're commonly used in payment processing, inventory management, and user state updates.

#### Follow-up Questions
1. How do you handle network partitions in distributed lock systems?
2. What's the difference between pessimistic and optimistic locking?
3. How do you implement lock hierarchies to prevent deadlocks?

---

## Summary

This comprehensive collection covers 38 advanced Promise and async/await interview questions, including:

- **15 Frequently Asked Questions** covering core concepts
- **10 Company-Specific Questions** from FAANG and other top companies  
- **8 Advanced/Expert Level Questions** for senior and staff engineers
- **5 Behavioral Questions** about debugging and production experience
- **5 Real-World Scenarios** from fintech and healthcare domains

Each question includes multiple answer formats (quick/detailed), real-world context, common mistakes, and follow-up questions to help candidates prepare thoroughly for technical interviews.

The content emphasizes practical application, production debugging scenarios, and advanced patterns that senior backend engineers encounter in real-world systems.